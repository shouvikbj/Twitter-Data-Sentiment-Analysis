# -*- coding: utf-8 -*-
"""Twitter Data Sentiment Analysis Using Python.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cfFk191BnhtyUDg2vQgBWoora0mPc2A6
"""

# Description: This is a sentiment analysis program that parses the tweets fetched from Twitter using Python

# import the libraries

import tweepy
from textblob import TextBlob
from wordcloud import WordCloud
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
plt.style.use("fivethirtyeight")

# Load the CSV to Googke Colab

# from google.colab import files
# uploaded = files.upload()

# Get the data

log = pd.read_csv("Login.csv")

# Store your own Twitter API Credentials in a "Login.csv" file for the steps below to work


# Twitter API Credentials

consumerKey = log["key"][0]
consumerSecret = log["key"][1]
accessToken = log["key"][2]
accessTokenSecret = log["key"][3]

# Create the authentication object

authenticate = tweepy.OAuthHandler(consumerKey, consumerSecret)

# Set the access token and access token secret

authenticate.set_access_token(accessToken, accessTokenSecret)

# Create the API object while passing in the auth information

api = tweepy.API(authenticate, wait_on_rate_limit=True)

# Extract 100 tweets from the twitter user

posts = api.user_timeline(screen_name="BillGates", count=100, lang="en", tweet_mode="extended")

# Print last 5 twees from the account

print("Show the 5 recent tweets: \n")
i=1
for tweet in posts[0:5]:
  print(str(i) +") " + tweet.full_text+"\n")
  i+=1

# Create a dataframe with a column called tweets

df = pd.DataFrame([tweet.full_text for tweet in posts], columns=["Tweets"])

# Showing the first 5 rows of data

df.head()

# Clean the text

# Create a function to clean the tweets

def cleanText(text):
  text = re.sub(r"@[A-Za-z0-9]+", "", text) # Removes @mentions
  text = re.sub(r"#", "", text) # Removing the '#' symbol
  text = re.sub(r"RT[\s]+", "", text) # Removing RT
  text = re.sub(r"https?:\/\/\S+", "", text) # Removing the hyper links

  return text

# Cleaning the text

df["Tweets"] = df["Tweets"].apply(cleanText)

# Show the cleaned text

df

# Create a function to get the subjectivity

def getSubjectivity(text):
  return TextBlob(text).sentiment.subjectivity

# Create a function to get the polarity

def getPolarity(text):
  return TextBlob(text).sentiment.polarity

# Create two new columns -> "subjectivity" && "polarity"

df["Subjectivity"] = df["Tweets"].apply(getSubjectivity)
df["Polarity"] = df["Tweets"].apply(getPolarity)

# Show the new DataFrame with the new Columns

df

# Plot the Word Cloud

allWords= " ".join([tweets for tweets in df["Tweets"]])
wordCloud = WordCloud(width=500, height=300, random_state=21, max_font_size=119).generate(allWords)

plt.imshow(wordCloud, interpolation="bilinear")
plt.axis("off")
plt.show()

# Create a function to compute the negative, neutral and positive analysis

def getAnalysis(score):
  if score<0:
    return "Negative"
  elif score==0:
    return "Neutral"
  else:
    return "Positive"

df["Analysis"] = df["Polarity"].apply(getAnalysis)

# Show the dataframe
df

# Print all of the positive tweets

j=1
sortedDF = df.sort_values(by=["Polarity"])
for i in range(0, sortedDF.shape[0]):
  if sortedDF["Analysis"][i] == "Positive":
    print(str(j)+") "+sortedDF["Tweets"][i])
    print()
    j+=1

# Print the negative tweets

j=1
sortedDF2 = df.sort_values(by=["Polarity"], ascending=False)
for i in range(0, sortedDF2.shape[0]):
  if sortedDF2["Analysis"][i] == "Negative":
    print(str(j)+") "+sortedDF2["Tweets"][i])
    print()
    j+=1

# Print the neutral tweets

j=1
sortedDF3 = df.sort_values(by=["Polarity"])
for i in range(0, sortedDF3.shape[0]):
  if sortedDF3["Analysis"][i] == "Neutral":
    print(str(j)+") "+sortedDF3["Tweets"][i])
    print()
    j+=1

# Plot the Polarity and Subjectivity

plt.figure(figsize=(8,6))
for i in range(0, df.shape[0]):
  plt.scatter(df["Polarity"][i], df["Subjectivity"][i], color="Blue")

plt.title("Sentiment Analysis")
plt.xlabel("Polarity")
plt.ylabel("Subjectivity")
plt.show()

# Get the percentage of positive tweets

ptweets = df[df.Analysis == "Positive"]
ptweets = ptweets["Tweets"]

positive_percentage = round((ptweets.shape[0] / df.shape[0])*100, 1)
print(f"Positive Tweets: {positive_percentage} %")

# Get the percentage of neutral tweets

ptweets = df[df.Analysis == "Neutral"]
ptweets = ptweets["Tweets"]

neutral_percentage = round((ptweets.shape[0] / df.shape[0])*100, 1)
print(f"Neutral Tweets: {neutral_percentage} %")

# Get the percentage of negative tweets

ptweets = df[df.Analysis == "Negative"]
ptweets = ptweets["Tweets"]

negative_percentage = round((ptweets.shape[0] / df.shape[0])*100, 1)
print(f"Negative Tweets: {negative_percentage} %")

# Show the value counts

df["Analysis"].value_counts()

# plot and visualize the counts in Bar Graph

plt.title("Sentiment Analysis")
plt.xlabel("Sentiment")
plt.ylabel("Counts")
df["Analysis"].value_counts().plot(kind="bar")
plt.show()

# Show the value counts

df["Analysis"].value_counts()

# plot and visualize the counts in Pie Chart

plt.title("Sentiment Analysis")
plt.xlabel("Sentiment")
df["Analysis"].value_counts().plot(kind="pie")
plt.show()

